{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We will be using sports-reference.com to gather all of our data. They are a great site with a tons of stats for every major sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First we want to scrape the team stats of all available NCAA Men's Basketball teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#url's for 2018 and 2019 regular season\n",
    "basic_stats_url19 = 'https://www.sports-reference.com/cbb/seasons/2019-school-stats.html'\n",
    "basic_stats_url18 = 'https://www.sports-reference.com/cbb/seasons/2018-school-stats.html'\n",
    "\n",
    "#list holding the header of each stat category\n",
    "basic_stats = ['SCHOOL','RANK','GAMES','WINS','LOSS','W/L%','SRS','SOS','CONF. W','CONF. L','HOME W','HOME L','AWAY W','AWAY L','POINTS SCORED','POINTS ALLOWED','MINUTES PLAYED','FG','FGA','FG%','3P','3PA','3P%','FT','FTA','FT%','OFFENSIVE REBOUNDS','TOTAL REBOUNDS','ASISTS','STEALS','BLOCKS','TURN OVERS','PF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function scrapes the given webpage and saves the information to a csv file\n",
    "#Setting it up in this way allows us to grab either basic or advanced stats of every team in any year we choose\n",
    "def NCAA_scrape_teams(url,csv_name,stats_cols):\n",
    "\n",
    "    #Creates an empty csv file with a header of each category we will be scraping \n",
    "    with open(csv_name,'w',newline='') as writefile:\n",
    "        writer = csv.writer(writefile)\n",
    "        writer.writerow(stats_cols)\n",
    "\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    data = soup.find(class_='table_outer_container').find('tbody').find_all('tr')\n",
    "\n",
    "\n",
    "    for i in data:#this for loop grabs each row of stats and picks out the school name\n",
    "        stats = []\n",
    "        try: #try statement because the table is broken up by headers\n",
    "            stats.append(i.find('a').contents[0])\n",
    "\n",
    "            for j in i.find_all(class_='right'): #this loop iterates through each col of each row of stats, saving them to a list\n",
    "\n",
    "                try:\t#try statement because their is a random gap in the table\t\n",
    "                    stats.append(float(j.contents[0]))\n",
    "\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "            #Our stats list will hold one team and all of its respective stats\n",
    "            #We need to append it to the csv file we created above before it gets rewritten at the start of the first for loop\n",
    "            with open(csv_name,'a',newline='') as appendfile:\n",
    "                append = csv.writer(appendfile)\n",
    "                \n",
    "                append.writerow(stats)\n",
    "\n",
    "        except AttributeError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Call the function and save all of 2019 and 2018 team statistics to a csv file\n",
    "\n",
    "NCAA_scrape_teams(basic_stats_url19,'NCAA_Team_Data_Basic19.csv',basic_stats)\n",
    "NCAA_scrape_teams(basic_stats_url18,'NCAA_Team_Data_Basic18.csv',basic_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we want to gather the results of each regular season game from any given NCAA season\n",
    "\n",
    "#2019 Season\n",
    "base_games19 ='https://www.sports-reference.com/cbb/play-index/matchup_finder.cgi?request=1&year_min=2019&year_max=2019&school_id=&opp_id=&game_type=A&game_month=&game_location=&game_result=&is_overtime=&comp_school=le&comp_opp=le&rank_school=ANY&rank_opp=ANY&order_by=date_game&order_by_asc=&offset='\n",
    "pages19 = 11700\n",
    "\n",
    "#2018 Season\n",
    "base_games18 = 'https://www.sports-reference.com/cbb/play-index/matchup_finder.cgi?request=1&year_min=2018&year_max=2018&school_id=&opp_id=&game_type=A&game_month=&game_location=&game_result=&is_overtime=&comp_school=le&comp_opp=le&rank_school=ANY&rank_opp=ANY&order_by=date_game&order_by_asc=&offset='\n",
    "pages18 = 11600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NCAA_reg_season_scraper(base_url, page_num, csv_name):\n",
    "\n",
    "    #to cycle through the many pages of basketball games, we need to create list of all the webpages using our base url \n",
    "    scroll = []\n",
    "    for i in range(0,page_num,100):\n",
    "        scroll.append(base_url + str(i))\n",
    "\n",
    "    #Create a new csv file with our header\n",
    "    with open(csv_name,'w',newline='') as writefile:\n",
    "            writer = csv.writer(writefile)\n",
    "            writer.writerow(['Date','Team','Rank','Away?','Opponent','Opp Rank','W/L','Points','Opp Points','Point Diff.','OT'])\n",
    "\n",
    "    #This part of our function will be similar in style to our above function\n",
    "    for url in scroll:\n",
    "\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text,'html.parser')\n",
    "        data = soup.find(class_='table_outer_container').find('tbody').find_all('tr')\n",
    "\n",
    "        for i in data:\n",
    "            holder = []\n",
    "            for j in i.find_all('td'):\n",
    "                try:\n",
    "                    holder.append(int(j.get_text()))\n",
    "\n",
    "                except ValueError:\n",
    "                    holder.append(j.get_text())\n",
    "\n",
    "                except IndexError:\n",
    "                    continue\n",
    "\n",
    "            try:     #we are going to delete some blank spaces in our scraped data\n",
    "                del holder[1]\n",
    "                del holder[7]\n",
    "                del holder[10]\n",
    "\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "            with open(csv_name,'a',newline='') as appendfile:\n",
    "                append = csv.writer(appendfile)\n",
    "                if len(holder) == 0: #Deletes the blank rows in the original table \n",
    "                    pass\n",
    "                else:\n",
    "                    append.writerow(holder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Call the function to save all of the 2019 and 2018 to a respective csv file\n",
    "\n",
    "NCAA_reg_season_scraper(base_games19,pages19,'NCAA_Reg_Season19.csv')\n",
    "NCAA_reg_season_scraper(base_games18,pages18,'NCAA_Reg_Season18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
