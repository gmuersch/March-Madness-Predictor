{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we are going to read the data we scraped and use it to train a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_stats_basic19 = r\"C:\\Python\\March Madness\\NCAA_Team_Data_basic19.csv\"\n",
    "path_stats_basic18 = r\"C:\\Python\\March Madness\\NCAA_Team_Data_basic18.csv\"\n",
    "\n",
    "# df of all team stats for each year\n",
    "df_stats19 = pd.read_csv(path_stats_basic19)\n",
    "df_stats18 = pd.read_csv(path_stats_basic18)\n",
    "\n",
    "# df picking out our stats we will use as features in our model, this is useful for our our match_stats functions below\n",
    "df_features19 = df_stats19[['SCHOOL','SRS','FG%','3P%', 'FT%']]\n",
    "df_features18 = df_stats18[['SCHOOL','SRS','FG%','3P%', 'FT%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_games19 = r\"C:\\Python\\March Madness\\NCAA_Reg_Season19.csv\"\n",
    "path_games18 = r\"C:\\Python\\March Madness\\NCAA_Reg_Season18.csv\"\n",
    "\n",
    "# df of all games played for each year\n",
    "df_games19 = pd.read_csv(path_games19)\n",
    "df_games18 = pd.read_csv(path_games18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since we have data on games that include some very small schools \n",
    "# lets create a function to count how many games we do not have team data for (to make sure it is not a large amount which would indicate an issue)\n",
    "def game_error_counter(df_games,df_stats):\n",
    "    errors = 0\n",
    "    for index,row in df_games.iterrows():\n",
    "        try:\n",
    "            df_stats.loc[df_stats['SCHOOL']==row[1]].values[0][2:]\n",
    "        except IndexError:\n",
    "            df_games = df_games.drop([index])\n",
    "            errors +=1\n",
    "    print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "game_error_counter(df_games19,df_stats19)\n",
    "game_error_counter(df_games18,df_stats18)\n",
    "\n",
    "# 63 and 60 games respecitvely, we can ignore these games from our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function calculates the match stats of each regular season game\n",
    "# skipping the games we dont have team data for and saves the result to a list\n",
    "reg_season = []\n",
    "def match_stats_reg_season(df_games,df_features):\n",
    "    for index,row in df_games.iterrows():\n",
    "        if index%2==0: # Each game has 2 rows (one for each team) this will get rid of the redundant data\n",
    "            try:\n",
    "                reg_season.append(np.append(df_features.loc[df_features['SCHOOL']==row[1]].values[0][1:].astype(float) - df_features.loc[df_features['SCHOOL']==row[4]].values[0][1:].astype(float),[row[6]]))\n",
    "            except IndexError:\n",
    "                pass\n",
    "    return reg_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_stats_reg_season(df_games19,df_features19);\n",
    "match_stats_reg_season(df_games18,df_features18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now our data is ready to be used to train our model\n",
    "\n",
    "features = ['SRS','FG%','3P%','FT%']\n",
    "\n",
    "df_match_stats_reg_season = pd.DataFrame(columns=['SRS','FG%','3P%','FT%','W/L'],data=reg_season)\n",
    "df_match_stats_reg_season['W/L'] = pd.get_dummies(df_match_stats_reg_season['W/L']) #encode the categorical variables\n",
    "# 0 is a win, 1 is a loss\n",
    "\n",
    "\n",
    "\n",
    "all_x = df_match_stats_reg_season[features]\n",
    "all_y = df_match_stats_reg_season['W/L'] \n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(all_x, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Serializing our model to a file called finalized_model.sav\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76385104450499541"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can check the accuracy score by splitting our training data into two sets\n",
    "# We will train the model with one set and predict the other to test accuracy\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(all_x,all_y,test_size = 0.2, random_state=0)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "holdout_predicitons = model.predict(xTest)\n",
    "\n",
    "score = accuracy_score(yTest, holdout_predicitons)\n",
    "\n",
    "score\n",
    "\n",
    "# Our model predicts with an accuracy of 76.385%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
